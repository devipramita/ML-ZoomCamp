{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs vs Cats Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an image classification task of classifying dogs and cats. <br />\n",
    "Dataset can be downloaded from [here](https://www.kaggle.com/c/dogs-vs-cats/data) <br />\n",
    "Please split dataset (both cat & dog label) into different folders, take the 1st 10k images of each label to train and the rest go to validation. <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 cat.1447.jpg (150, 150, 3) cat\n",
      "1000 cat.1898.jpg (150, 150, 3) cat\n",
      "1500 cat.2347.jpg (150, 150, 3) cat\n",
      "2000 cat.2798.jpg (150, 150, 3) cat\n",
      "2500 cat.3247.jpg (150, 150, 3) cat\n",
      "3000 cat.3698.jpg (150, 150, 3) cat\n",
      "3500 cat.4147.jpg (150, 150, 3) cat\n",
      "4000 cat.4598.jpg (150, 150, 3) cat\n",
      "4500 cat.548.jpg (150, 150, 3) cat\n",
      "5000 cat.999.jpg (150, 150, 3) cat\n",
      "5500 dog.1447.jpg (150, 150, 3) dog\n",
      "6000 dog.1898.jpg (150, 150, 3) dog\n",
      "6500 dog.2347.jpg (150, 150, 3) dog\n",
      "7000 dog.2798.jpg (150, 150, 3) dog\n",
      "7500 dog.3247.jpg (150, 150, 3) dog\n",
      "8000 dog.3698.jpg (150, 150, 3) dog\n",
      "8500 dog.4147.jpg (150, 150, 3) dog\n",
      "9000 dog.4598.jpg (150, 150, 3) dog\n",
      "9500 dog.548.jpg (150, 150, 3) dog\n",
      "10000 dog.999.jpg (150, 150, 3) dog\n"
     ]
    }
   ],
   "source": [
    "train_images = []\n",
    "train_classes = []\n",
    "i = 0\n",
    "for filename in os.listdir(\"train_sliced/\"):\n",
    "    img = load_img(\"train_sliced/\"+filename, target_size=(150,150))\n",
    "    img = np.array(img)\n",
    "#     img = np.expand_dims(img, axis=0)\n",
    "    train_images.append(img)\n",
    "    train_classes.append(filename.split(\".\")[0])\n",
    "    i += 1\n",
    "    if i % 500 == 0:\n",
    "        print(i, filename, img.shape, filename.split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 cat.10499.jpg (150, 150, 3) cat\n",
      "1000 cat.10999.jpg (150, 150, 3) cat\n",
      "1500 cat.11499.jpg (150, 150, 3) cat\n",
      "2000 cat.11999.jpg (150, 150, 3) cat\n",
      "2500 dog.10499.jpg (150, 150, 3) dog\n",
      "3000 dog.10999.jpg (150, 150, 3) dog\n",
      "3500 dog.11499.jpg (150, 150, 3) dog\n",
      "4000 dog.11999.jpg (150, 150, 3) dog\n"
     ]
    }
   ],
   "source": [
    "val_images = []\n",
    "val_classes = []\n",
    "i = 0\n",
    "for filename in os.listdir(\"validation_sliced/\"):\n",
    "    img = load_img(\"validation_sliced/\"+filename, target_size=(150,150))\n",
    "    img = np.array(img)\n",
    "#     img = np.expand_dims(img, axis=0)\n",
    "    val_images.append(img)\n",
    "    val_classes.append(filename.split(\".\")[0])\n",
    "    i += 1\n",
    "    if i % 500 == 0:\n",
    "        print(i, filename, img.shape, filename.split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "train_labels = np.expand_dims(le.fit_transform(train_classes), axis=1)\n",
    "val_labels = np.expand_dims(le.fit_transform(val_classes), axis=1)\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "val_labels = to_categorical(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.array(train_images)\n",
    "val_images = np.array(val_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 0.], dtype=float32), array([1., 0.], dtype=float32))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0], val_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[203, 164,  87],\n",
       "        [209, 170,  93],\n",
       "        [209, 170,  93],\n",
       "        ...,\n",
       "        [247, 206, 124],\n",
       "        [244, 204, 119],\n",
       "        [240, 201, 122]],\n",
       "\n",
       "       [[203, 164,  87],\n",
       "        [209, 170,  93],\n",
       "        [209, 170,  93],\n",
       "        ...,\n",
       "        [245, 207, 124],\n",
       "        [245, 204, 122],\n",
       "        [240, 201, 122]],\n",
       "\n",
       "       [[203, 164,  87],\n",
       "        [209, 170,  93],\n",
       "        [209, 170,  93],\n",
       "        ...,\n",
       "        [247, 209, 128],\n",
       "        [244, 206, 125],\n",
       "        [242, 203, 124]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[158, 124,  53],\n",
       "        [159, 125,  54],\n",
       "        [160, 126,  55],\n",
       "        ...,\n",
       "        [  3,   4,   0],\n",
       "        [  3,   4,   0],\n",
       "        [  2,   2,   0]],\n",
       "\n",
       "       [[154, 123,  56],\n",
       "        [155, 124,  57],\n",
       "        [158, 127,  60],\n",
       "        ...,\n",
       "        [  2,   2,   0],\n",
       "        [  2,   2,   0],\n",
       "        [  2,   2,   0]],\n",
       "\n",
       "       [[152, 121,  54],\n",
       "        [153, 122,  55],\n",
       "        [157, 126,  59],\n",
       "        ...,\n",
       "        [  2,   2,   0],\n",
       "        [  2,   2,   0],\n",
       "        [  2,   2,   0]]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.astype(\"float32\")/255\n",
    "val_images = val_images.astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.79607844, 0.6431373 , 0.34117648],\n",
       "        [0.81960785, 0.6666667 , 0.3647059 ],\n",
       "        [0.81960785, 0.6666667 , 0.3647059 ],\n",
       "        ...,\n",
       "        [0.96862745, 0.80784315, 0.4862745 ],\n",
       "        [0.95686275, 0.8       , 0.46666667],\n",
       "        [0.9411765 , 0.7882353 , 0.47843137]],\n",
       "\n",
       "       [[0.79607844, 0.6431373 , 0.34117648],\n",
       "        [0.81960785, 0.6666667 , 0.3647059 ],\n",
       "        [0.81960785, 0.6666667 , 0.3647059 ],\n",
       "        ...,\n",
       "        [0.9607843 , 0.8117647 , 0.4862745 ],\n",
       "        [0.9607843 , 0.8       , 0.47843137],\n",
       "        [0.9411765 , 0.7882353 , 0.47843137]],\n",
       "\n",
       "       [[0.79607844, 0.6431373 , 0.34117648],\n",
       "        [0.81960785, 0.6666667 , 0.3647059 ],\n",
       "        [0.81960785, 0.6666667 , 0.3647059 ],\n",
       "        ...,\n",
       "        [0.96862745, 0.81960785, 0.5019608 ],\n",
       "        [0.95686275, 0.80784315, 0.49019608],\n",
       "        [0.9490196 , 0.79607844, 0.4862745 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.61960787, 0.4862745 , 0.20784314],\n",
       "        [0.62352943, 0.49019608, 0.21176471],\n",
       "        [0.627451  , 0.49411765, 0.21568628],\n",
       "        ...,\n",
       "        [0.01176471, 0.01568628, 0.        ],\n",
       "        [0.01176471, 0.01568628, 0.        ],\n",
       "        [0.00784314, 0.00784314, 0.        ]],\n",
       "\n",
       "       [[0.6039216 , 0.48235294, 0.21960784],\n",
       "        [0.60784316, 0.4862745 , 0.22352941],\n",
       "        [0.61960787, 0.49803922, 0.23529412],\n",
       "        ...,\n",
       "        [0.00784314, 0.00784314, 0.        ],\n",
       "        [0.00784314, 0.00784314, 0.        ],\n",
       "        [0.00784314, 0.00784314, 0.        ]],\n",
       "\n",
       "       [[0.59607846, 0.4745098 , 0.21176471],\n",
       "        [0.6       , 0.47843137, 0.21568628],\n",
       "        [0.6156863 , 0.49411765, 0.23137255],\n",
       "        ...,\n",
       "        [0.00784314, 0.00784314, 0.        ],\n",
       "        [0.00784314, 0.00784314, 0.        ],\n",
       "        [0.00784314, 0.00784314, 0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 128)     3584      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 74, 74, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 72, 64)        73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 82944)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2654240   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 2,731,682\n",
      "Trainable params: 2,731,682\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(128, (3,3), activation=\"relu\", input_shape=(150,150,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv2D(64, (3,3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=SGD(lr=0.002, momentum=0.8), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 1118s 112ms/step - loss: 0.6908 - accuracy: 0.5246 - val_loss: 0.6889 - val_accuracy: 0.5429\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 1124s 112ms/step - loss: 0.6855 - accuracy: 0.5470 - val_loss: 0.6823 - val_accuracy: 0.5552\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 1157s 116ms/step - loss: 0.6781 - accuracy: 0.5640 - val_loss: 0.6721 - val_accuracy: 0.6055\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 1108s 111ms/step - loss: 0.6692 - accuracy: 0.5833 - val_loss: 0.6599 - val_accuracy: 0.6234\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 798s 80ms/step - loss: 0.6558 - accuracy: 0.6039 - val_loss: 0.6631 - val_accuracy: 0.6265\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 880s 88ms/step - loss: 0.6423 - accuracy: 0.6177 - val_loss: 0.6597 - val_accuracy: 0.5857\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 881s 88ms/step - loss: 0.6329 - accuracy: 0.6281 - val_loss: 0.6238 - val_accuracy: 0.6474\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 870s 87ms/step - loss: 0.6164 - accuracy: 0.6497 - val_loss: 0.6125 - val_accuracy: 0.6545\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 681s 68ms/step - loss: 0.6062 - accuracy: 0.6574 - val_loss: 0.5925 - val_accuracy: 0.6770\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 654s 65ms/step - loss: 0.5953 - accuracy: 0.6711 - val_loss: 0.5838 - val_accuracy: 0.6914\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, train_labels, validation_data=(val_images, val_labels), epochs=10, batch_size=16, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
